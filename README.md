# Malicious-URL-Detector
This Python program detects malicious URLs using rules and machine learning, helping users identify and avoid online threats.

The provided code implements a Malicious URL Detector that classifies URLs as either malicious or non-malicious using a hybrid approach combining rule-based techniques and machine learning. The system features a user-friendly interface, allowing users to analyze individual URLs or scan files containing multiple URLs. Its flexible design makes it suitable for both quick checks and batch processing. The primary purpose of this Python script is to help family and friends determine whether a URL they want to visit or have received is safe. By testing the URL in the script before accessing it in a browser, users can avoid potential threats and ensure safer online interactions. 

The program features a user-friendly menu for analyzing either a single URL or a file of URLs. For single URL analysis, it flags less secure links (e.g., http://) and provides color-coded results, with malicious links highlighted in red and safe links in green. For file-based analysis, it processes URLs line by line, leveraging detection and machine learning techniques to efficiently handle large datasets. Robust error handling is implemented to manage invalid inputs and file-not-found errors. To address potential false positives, the program allows users to rescan specific URLs to verify the accuracy of the results.

To develop the detector, a dataset of example URLs was created, including non-malicious ones (trusted domains like Google, Amazon, and Yahoo) and malicious ones (e.g., phishing domains and URLs with suspicious patterns). The dataset was built by researching GitHub repositories and other sources of known malicious URLs to ensure a wide variety of patterns for accurate detection.

A Naive Bayes classifier was trained using this data, leveraging textual features such as URL length, domain structure, and character patterns. The code uses the TfidfVectorizer from scikit-learn to transform the URLs into numerical features by extracting character n-grams and calculating their TF-IDF score. Additional numerical features, including URL length, number of dots, digits, and special characters, are extracted using the extract_features method. This method assesses the URL against various requirements to determine if it matches the machine learning model. The goal is to automate the training process, but currently, the script uses prediction to discover the state of unseen URLs. Furthermore, a rule-based system using regular expressions detects unsafe patterns like .exe file extensions, HTTP links, and suspicious TLDs (e.g., .tk).


Ultimately, this system strikes a balance between flexibility, accuracy, and usability, making it a practical tool for detecting unsafe links in both individual and bulk scenarios. As of right now certain weakness that are in the script is the small dataset for training the model, having the model understand unseen URLs, and the use of the naive Bayes classifier could be the most effective algorithm but it needs to be able to understand URLs that are not int eh dataset as well. By developing this script has deepened my understanding of the technical skills required to effectively detect malicious URLs. As I continue my journey to enhance my expertise in cybersecurity, I plan to refine this script by incorporating the latest advancements in technology and updating its modules. This iterative process will ensure the tool remains relevant and robust, reflecting my growth in the field and my commitment to creating reliable cybersecurity solutions.
